---
layout: post
title:  "Extracting frames from a GIF in JS"
date:   2020-07-27 14:10:00 +0200
tags: meta
---

If you just want to know how to this without any fuss, you can go straight to the <a href="#solution">solution</a>, or see the finished product on [github](https://github.com/jprochazk/sprite-utils/blob/master/src/gif.ts).

##### <a name="backstory" href="#backstory">Some backstory</a>

I've been working on a game project for the past few months. This week, I wanted to implement animated sprites. The actual technique is simple:

1. Maintain an array of textures
2. Step to the next texture on each update
3. Wrap back to the first texture when you reach the end of the array

But then I stumbled upon a problem. How am I going to author these sprites? Will I have to maintain a huge spritesheet containing every frame of every animation? Will I split each frame of an animation into its own file? 

I quickly realised that this is going to be a bit more complex than I thought. I decided to create animated sprites as .gif files, because it's the simplest way to immediately see the animation in action, and it means I can avoid having to load the animated sprite into my game each time I want to see how it will look. GIF files also allow for specifying delays inbetween frames, allowing for fine control over the animation. It was the perfect file format, but then I stumbled upon a problem:

There is no native API in JavaScript to extract the frames out of a GIF file!

So I went on the hunt for libraries which can do this. The GIF format is standardised, so there must be parsers, decoders and encoders that other people have made. And that's exactly right, I actually found many different options, such as [omggif](https://github.com/deanm/omggif), [gifwrap](https://github.com/jtlapp/gifwrap), [libgif](https://github.com/buzzfeed/libgif-js), and a few others. The one I ended up using is [gifuct](https://github.com/matt-way/gifuct-js). I'll talk about why a bit later.

##### <a name="problem" href="#problem">The problem</a>

GIF images are delta encoded, where each subsequent frame only contains the pixels that are *different* from the last frame's pixels. Here's an example of that:

The complete gif looks like this:

![jblack-0]

And one of the frames, without decompression, looks like this (with "transparent" pixels converted to white):

![jblack-1]

Now, I could use one of those online GIF decompression tools, and I'd be set. While this is true, that would be an extra step that I would have to take each time I wanted to update a sprite, and I wanted a simple and clean sprite pipeline.

Luckily, [gifuct](https://github.com/matt-way/gifuct-js) provides a utility function which generates "patches" that you can use to decompress the GIF file. I could use this to decompress the GIF into an array of full frames, which I could load into my game as WebGL textures, and easily display them.

##### <a name="solution" href="#solution">The solution</a>

I wanted two things out of the GIF: Each decompressed frame, and the delay between each frame.

First is the loading and parsing of the GIF, along with generating the decompression patches. The `gifuct` api is very simple, it's just two functions, and loading the file would be done using [`fetch(path)`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) in the browser, or [`fs.readFile(path)`](https://nodejs.org/api/fs.html#fs_fs_readfile_path_options_callback) in node.js. My environment is node.js, so I'm using that.

{% highlight js %}
import * as fs from "fs";
import { parseGIF, decompressFrames } from "gifuct-js";

// I'm using readFileSync because it simplifies the control flow
const frames = decompressFrames(parseGIF(fs.readFileSync(path)), true);
{% endhighlight %}

Each frame in the `frames` array will be an object with these properties:
{% highlight js %}
{
    // the dimensions of the gif frame (see disposal method)
    dims: {
        top: 0,
        left: 10,
        width: 100,
        height: 50
    },
    // the time in milliseconds that this frame should be shown
    delay: 50,
    // Color converted patch information for drawing
    patch: Uint8ClampedArray
 }
{% endhighlight %}
There are some other properties, but these are the ones that are interesting to us.

To actually extract the frames, we have to draw each frame onto a canvas. In Node, there is no built-in canvas, so we have to use another library, [node-canvas](https://github.com/Automattic/node-canvas) which provides both the utility to create a canvas and the standard canvas API.

To actually draw the frames, we'll be using two canvases. One will be used to contain each frame difference, and the other will contain the current state of the entire image. This will become clear later.

{% highlight js %}
// I'm shamelessly indexing an array without checking the bounds first,
// so of course you'd check if frame.length > 0 and if not, throw an error.
// ...right? :)
const { width, height } = frame[0].dims;
const drawCanvas = createCanvas(width, height);
const dataCanvas = createCanvas(width, height);
const drawCtx = drawCanvas.getContext("2d");
const dataCtx = dataCanvas.getContext("2d");
{% endhighlight %}

Now we're ready to process each frame. We'll create an array to contain our processed frames, along with a helper variable which will hold the current frame's [`ImageData`](https://developer.mozilla.org/en-US/docs/Web/API/ImageData).
{% highlight js %}
const processedFrames = [];
let frameImageData = null;
for (const frame of frames) { 
    // If the frameImageData is null (meaning this is the first frame)
    // OR the dimensions have changed, then update the dimensions of
    // the ImageData to match the current frame's dimensions
    if (!frameImageData ||
        frame.dims.width !== frameImageData.width ||
        frame.dims.height !== frameImageData.height) {
        dataCanvas.width = frame.dims.width;
        dataCanvas.height = frame.dims.height;
        frameImageData = createImageData(frame.dims.width, frame.dims.height);
    }

    // ...
}
{% endhighlight %}

`frame.patch` is a [`Uint8ClampedArray`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8ClampedArray), which is convenient, because that is the type of buffer that [`ImageData`](https://developer.mozilla.org/en-US/docs/Web/API/ImageData) also uses, which means we can directly apply it without any transformations:

{% highlight js %}
// Set the current frame ImageData
frameImageData.data.set(frame.patch);
// Then put that onto our temporary canvas
dataCtx.putImageData(frameImageData, 0, 0);
// And draw our temporary canvas onto the main one
drawCtx.drawImage(dataCanvas, frame.dims.left, frame.dims.top);
{% endhighlight %}

Because we didn't clear the canvas inbetween frames, it still contains the data from the previous frame. By laying the patch on top of the previous frame, we've built the next frame. 

We can retrieve this frame in various ways. One way is to get the [`ImageData`](https://developer.mozilla.org/en-US/docs/Web/API/ImageData) from the canvas:
{% highlight js %}
const data = drawCtx.getImageData();
{% endhighlight %}

Another is to encode the canvas to base64:
{% highlight js %}
const data = drawCanvas.toDataURL();
{% endhighlight %}

Finally, we push the data into the `processedFrames` array:
{% highlight js %}
processedFrames.push({ delay: frame.delay, data });
{% endhighlight %}

And that's it- now you can use the decompressed frames for an arbitrary purpose, such as creating `Image` elements out of them and displaying them on the page.

The entire code is [available on github](https://github.com/jprochazk/sprite-utils/blob/master/src/gif.ts).

[jblack-0]: /assets/img/posts/jblack.gif
[jblack-1]: /assets/img/posts/jblack-incomplete.png



